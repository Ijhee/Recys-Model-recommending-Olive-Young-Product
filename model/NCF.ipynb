{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Train / Val Data Preprocessing\n",
        "- Movie Lens data 전처리"
      ],
      "metadata": {
        "id": "wwtWCXSM65Ks"
      },
      "id": "wwtWCXSM65Ks"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFJv7Lk8sIcc",
        "outputId": "fe579007-8f2f-4f8f-e25c-508e36e9733b"
      },
      "id": "yFJv7Lk8sIcc",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "metadata": {
        "id": "VAv6tGa5zmrw"
      },
      "id": "VAv6tGa5zmrw",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "0MsBWboqHyT1"
      },
      "id": "0MsBWboqHyT1",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "ndf = pd.read_csv('/content/drive/MyDrive/BOAZ/분석/BASE/MINI2/DATA//ratings.csv')"
      ],
      "metadata": {
        "id": "wvicT6M-z_qk"
      },
      "id": "wvicT6M-z_qk",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 유저별로 아이템 개수가 너무 많으면 데이터의 행 개수가 너무 많아져서, 아이템 개수를 제한했음\n",
        "temp = pd.DataFrame(ndf['userId'].value_counts())\n",
        "temp['index']=temp.index\n",
        "temp.reset_index(drop=True,inplace=True)\n",
        "temp.columns = ['item_buy','userId']\n",
        "\n",
        "final_temp = temp[temp['item_buy']<=21]\n",
        "res = random.sample(list(final_temp['userId']), 6277)\n",
        "sample_df = ndf[ndf['userId'].isin(res)]\n",
        "sample_df.reset_index(inplace=True,drop=True)\n",
        "\n",
        "num_user = sample_df['userId'].nunique()\n",
        "num_item = sample_df['movieId'].nunique()"
      ],
      "metadata": {
        "id": "hM8IOtTR4_Yz"
      },
      "id": "hM8IOtTR4_Yz",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 먼저 데이터셋 encoding\n",
        "user_encoder, user_decoder = {}, {}\n",
        "\n",
        "# label encoding이라고 생각\n",
        "for idx, user_id in enumerate(sample_df['userId'].unique()):\n",
        "    user_encoder[user_id] = idx\n",
        "    user_decoder[idx] = user_id\n",
        "\n",
        "# label encoding이라고 생각\n",
        "item_encoder, item_decoder = {}, {}\n",
        "for idx, item_id in enumerate(sample_df['movieId'].unique()):\n",
        "    item_encoder[item_id] = idx\n",
        "    item_decoder[idx] = item_id\n",
        "    \n",
        "# 추후에 Embedding 과정을 거쳐서 보다 dense하게 만들어주어야함.\n",
        "##torch.nn.Embedding(num_embeddings=len(ratings_df['mbrNo']),embedding_dim = ratings_df['mbrNo'].nunqiue())\n",
        "\n",
        "sample_df['en_userId'] = sample_df['userId'].apply(lambda x : user_encoder[x])\n",
        "sample_df['en_movieId'] = sample_df['movieId'].apply(lambda x : item_encoder[x])\n",
        "sample_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "b_ZiGvee8Ybq",
        "outputId": "ae08558e-e8ad-4077-dbfb-03c91b4d7be2"
      },
      "id": "b_ZiGvee8Ybq",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b828e17259f5>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sample_df['en_userId'] = sample_df['userId'].apply(lambda x : user_encoder[x])\n",
            "<ipython-input-7-b828e17259f5>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sample_df['en_movieId'] = sample_df['movieId'].apply(lambda x : item_encoder[x])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating   timestamp  en_userId  en_movieId\n",
              "0      51        1     4.0  1510742879          0           0\n",
              "1      51       47     4.5  1510742884          0           1\n",
              "2      51       50     2.5  1530548826          0           2\n",
              "3      51      110     4.5  1510742881          0           3\n",
              "4      51      150     3.5  1510742877          0           4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46bd4370-e18d-4397-a549-3e9f6631587b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>en_userId</th>\n",
              "      <th>en_movieId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1510742879</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51</td>\n",
              "      <td>47</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1510742884</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>51</td>\n",
              "      <td>50</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1530548826</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51</td>\n",
              "      <td>110</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1510742881</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51</td>\n",
              "      <td>150</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1510742877</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46bd4370-e18d-4397-a549-3e9f6631587b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46bd4370-e18d-4397-a549-3e9f6631587b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46bd4370-e18d-4397-a549-3e9f6631587b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 논문에서 나와있던 Train / Test data를 Split 하는 방법\n",
        "# Train : 상호작용 O -> 유저별로 가장 최신 아이템을 제외한 나머지 아이템 = rating 1 / 상호작용 X -> 유저가 상호작용한 아이템을 제외한 아이템들 중에서 상호작용한 아이템 개수 * num_neg 만큼 rating 0\n",
        "# Test : 상호작용 O -> 유저별로 가장 최신 아이템 = rating 1 / 상호작용 X -> 유저가 상호작용한 아이템을 제외한 아이템들 중에서 99개 추출\n",
        "def split_data(df, num_neg = 2):\n",
        "    total_item_li = set(df['en_movieId'])\n",
        "    train_df = []\n",
        "    test_df = []\n",
        "    en_user_id_li = df['en_userId'].unique()\n",
        "    for en_user_id in tqdm(en_user_id_li):\n",
        "        pos_recomencder_li = df[df['en_userId'] == en_user_id]['en_movieId'].tolist()\n",
        "        neg_recomencder_li = np.random.choice(list(total_item_li - set(pos_recomencder_li)), num_neg * len(pos_recomencder_li), replace = False).tolist()\n",
        "        train_df += [[en_user_id, en_movieId, 1] for en_movieId in pos_recomencder_li[:-1]] + [[en_user_id, en_movieId, 0] for en_movieId in neg_recomencder_li]\n",
        "\n",
        "        neg_recomencder_li = np.random.choice(list(total_item_li - set(pos_recomencder_li)), 99, replace = False).tolist()\n",
        "        test_df += [[en_user_id, pos_recomencder_li[-1], 1]] + [[en_user_id, en_movieId, 0] for en_movieId in neg_recomencder_li]\n",
        "    \n",
        "    return train_df, test_df\n",
        "\n",
        "train_df, val_df = split_data(sample_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DwdePmtJhPh",
        "outputId": "58f87258-5c8c-42cd-ae27-4a3b4a78c797"
      },
      "id": "9DwdePmtJhPh",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6277/6277 [00:13<00:00, 448.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame(train_df); train_df.columns = ['userId','movieId','rating']\n",
        "val_df = pd.DataFrame(val_df); val_df.columns = ['userId','movieId','rating']"
      ],
      "metadata": {
        "id": "75pxdcMa8_sw"
      },
      "id": "75pxdcMa8_sw",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "C8mp4OP5aL32",
      "metadata": {
        "id": "C8mp4OP5aL32"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "data_dir = './data'\n",
        "model_dir = '/content/drive/MyDrive/BOAZ/분석/BASE/MINI2/model_path2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "50613a2d",
      "metadata": {
        "id": "50613a2d"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user = self.df.loc[idx][0].astype(int)\n",
        "        item = self.df.loc[idx][1].astype(int)\n",
        "        label = self.df.loc[idx][2]\n",
        "\n",
        "        return user, item, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e302ee1",
      "metadata": {
        "id": "5e302ee1"
      },
      "source": [
        "### GMF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dfb818b",
      "metadata": {
        "id": "4dfb818b"
      },
      "source": [
        "- GMF와 MLP의 embedding layer는 서로 다른 가중치로 학습. -> flexiblity up!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4a5052af",
      "metadata": {
        "id": "4a5052af"
      },
      "outputs": [],
      "source": [
        "# GMF는 user\n",
        "class GMF(nn.Module):\n",
        "    def __init__(self, num_user, num_item, num_factor):\n",
        "        super(GMF, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_user, num_factor) # embedding layer 통과 -> 보다 dense하게 만들어줌.\n",
        "        self.item_emb = nn.Embedding(num_item, num_factor)\n",
        "        \n",
        "        self.predict_layer = nn.Sequential(\n",
        "            nn.Linear(num_factor, 1, bias = False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self._init_weight_()\n",
        "    \n",
        "    def _init_weight_(self):\n",
        "        nn.init.normal_(self.user_emb.weight, std=0.01) # embedding layer 각각 정규분포 초기화\n",
        "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
        "        for m in self.predict_layer:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\") # nn.Linear는 he init 사용.\n",
        "    \n",
        "    def forward(self, user, item):\n",
        "        user_emb = self.user_emb(user)\n",
        "        item_emb = self.item_emb(item)\n",
        "\n",
        "        output = self.predict_layer(user_emb * item_emb) \n",
        "\n",
        "        return output.view(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33e0353e",
      "metadata": {
        "id": "33e0353e"
      },
      "source": [
        "### MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "89cdaea6",
      "metadata": {
        "id": "89cdaea6"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, num_user, num_item, num_factor, num_layers, dropout):\n",
        "        super(MLP, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.user_emb = nn.Embedding(num_user, num_factor)\n",
        "        self.item_emb = nn.Embedding(num_item, num_factor)\n",
        "\n",
        "        MLP_modules = []\n",
        "        input_size = num_factor * 2\n",
        "        for i in range(num_layers):\n",
        "            MLP_modules.append(nn.Dropout(p = self.dropout))\n",
        "            MLP_modules.append(nn.Linear(input_size, input_size // 2))\n",
        "            MLP_modules.append(nn.ReLU())\n",
        "            input_size = input_size // 2\n",
        "        self.MLP_layers = nn.Sequential(*MLP_modules) # num_layers 개수만큼의 mlp layer들이 있음.\n",
        "\n",
        "        self.predict_layer = nn.Sequential(\n",
        "            nn.Linear(input_size, 1, bias = False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self._init_weight_()\n",
        "    \n",
        "    def _init_weight_(self):\n",
        "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
        "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
        "        for m in self.MLP_layers:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "        \n",
        "        for m in self.predict_layer:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\")\n",
        "    \n",
        "    def forward(self, user, item):\n",
        "        user_emb = self.user_emb(user)\n",
        "        item_emb = self.item_emb(item)\n",
        "        \n",
        "        cat_emb = torch.cat((user_emb, item_emb), -1) # concat되어 들어감.\n",
        "\n",
        "        output = self.MLP_layers(cat_emb) \n",
        "\n",
        "        output = self.predict_layer(output)\n",
        "\n",
        "        return output.view(-1) # flatten\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd81a77d",
      "metadata": {
        "id": "fd81a77d"
      },
      "source": [
        "### NeuMF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "81891b0a",
      "metadata": {
        "id": "81891b0a"
      },
      "outputs": [],
      "source": [
        "# Neural MF는 GMF 와 MLP가 섞인 것.\n",
        "\n",
        "class NeuMF(nn.Module):\n",
        "    def __init__(self, GMF, MLP, num_factor,num_layers):\n",
        "        super(NeuMF, self).__init__()\n",
        "        self.gmf_user_emb = GMF.user_emb\n",
        "        self.gmf_item_emb = GMF.item_emb\n",
        "\n",
        "        self.mlp_user_emb = MLP.user_emb\n",
        "        self.mlp_item_emb = MLP.item_emb\n",
        "\n",
        "        self.mlp_layer = MLP.MLP_layers\n",
        "\n",
        "        self.predict_layer = nn.Sequential(\n",
        "            nn.Linear(num_factor + (num_factor // (2**(num_layers-1))), 1, bias = False),\n",
        "            nn.Sigmoid(),\n",
        "        ) # sigmoid function 통과 후 score 출력\n",
        "        self._init_weight_()\n",
        "    \n",
        "    def _init_weight_(self):\n",
        "        for m in self.predict_layer:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\")\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        gmf_user_emb = self.gmf_user_emb(user)\n",
        "        gmf_item_emb = self.gmf_item_emb(item)\n",
        "        gmf_output = gmf_user_emb * gmf_item_emb # GMF의 output\n",
        "\n",
        "        mlp_user_emb = self.mlp_user_emb(user)\n",
        "        mlp_item_emb = self.mlp_item_emb(item)\n",
        "        mlp_cat_emb = torch.cat((mlp_user_emb, mlp_item_emb), -1)\n",
        "        mlp_output = self.mlp_layer(mlp_cat_emb) # mlp의 output\n",
        "        \n",
        "        cat_output = torch.cat((gmf_output, mlp_output), -1) # mlp output, gmf ouptut concat\n",
        "\n",
        "        output = self.predict_layer(cat_output) \n",
        "\n",
        "        return output.view(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2ff0c3c",
      "metadata": {
        "id": "f2ff0c3c"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ce31f21a",
      "metadata": {
        "id": "ce31f21a"
      },
      "outputs": [],
      "source": [
        "def hit(target_item, pred_items):\n",
        "    if target_item in pred_items:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def ndcg(target_item, pred_items):\n",
        "    if target_item in pred_items:\n",
        "        idx = pred_items.index(target_item)\n",
        "        # 초기 인덱스가 0이기 때문에 +2 함\n",
        "        return np.reciprocal(np.log2(idx + 2))\n",
        "    return 0\n",
        "\n",
        "# test data로 성능 측정하는 함수\n",
        "# HR과 NDCG를 사용.\n",
        "# HR : 상위 K개의 아이템 중 실제 상호작용한 아이템을 맞춘 비율을 나타내는 지표.\n",
        "# NDCG : 추천된 아이템 순위와 사용자의 관심도를 고려하여 값이 높을수록 성능이 좋음.\n",
        "def metrics(model, test_loader, top_k):\n",
        "    model.eval()\n",
        "    HR, NDCG, pred_ratio, recommends = [], [],[],[]\n",
        "    with torch.no_grad():\n",
        "        for user, item, _ in test_loader:\n",
        "            user = user.to(device)\n",
        "            item = item.to(device)\n",
        "\n",
        "            predictions = model(user, item)\n",
        "            # 가장 높은 top_k개 선택\n",
        "            _, indices = torch.topk(predictions, top_k)\n",
        "            # 해당 상품 index 선택\n",
        "            recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
        "            # 정답값 선택\n",
        "            target_item = item[0].item()\n",
        "            HR.append(hit(target_item, recommends))\n",
        "            NDCG.append(ndcg(target_item, recommends))\n",
        "            pred_ratio += list(predictions)\n",
        "            recommends += list(recommends)\n",
        "\n",
        "    return np.mean(HR), np.mean(NDCG), pred_ratio, recommends\n",
        "\n",
        "# train 함수 구성\n",
        "def train(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for user, item, label in train_loader:\n",
        "        user = user.to(device)\n",
        "        item = item.to(device)\n",
        "        label = label.to(device)\n",
        "        label = label.float()\n",
        "\n",
        "        optimizer.zero_grad() \n",
        "        output = model(user, item)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    \n",
        "    # valid test\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for user, item, label in valid_loader:\n",
        "            user = user.to(device)\n",
        "            item = item.to(device)\n",
        "            label = label.to(device)\n",
        "            label = label.float()\n",
        "            \n",
        "            output = model(user, item)\n",
        "            val_loss = criterion(output, label)\n",
        "            \n",
        "            val_loss += val_loss.item()\n",
        "        valid_loss = val_loss / len(valid_loader)\n",
        "            \n",
        "    return train_loss, valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "214cc725",
      "metadata": {
        "id": "214cc725"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "batch_size = 128\n",
        "epochs = 40\n",
        "lr = 0.005\n",
        "num_factor = 64 \n",
        "num_layers = 4 \n",
        "dropout = 0.2\n",
        "top_k = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oliveyoung Dataset : Implicit Feedback 으로 전처리"
      ],
      "metadata": {
        "id": "Ya5VtwbjqUVX"
      },
      "id": "Ya5VtwbjqUVX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95f4582d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95f4582d",
        "outputId": "c59812ae-34b7-4d75-8c10-409e11267bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6277/6277 [00:03<00:00, 1814.04it/s]\n"
          ]
        }
      ],
      "source": [
        "ratings_df = pd.read_csv('/content/drive/MyDrive/BERT4Rec/olive_young_data.csv')\n",
        "# 먼저 데이터셋 encoding\n",
        "user_encoder, user_decoder = {}, {}\n",
        "\n",
        "# label encoding이라고 생각\n",
        "for idx, user_id in enumerate(ratings_df['mbrNo'].unique()):\n",
        "    user_encoder[user_id] = idx\n",
        "    user_decoder[idx] = user_id\n",
        "\n",
        "# label encoding이라고 생각\n",
        "item_encoder, item_decoder = {}, {}\n",
        "for idx, item_id in enumerate(ratings_df['goodsNm'].unique()):\n",
        "    item_encoder[item_id] = idx\n",
        "    item_decoder[idx] = item_id\n",
        "    \n",
        "# 추후에 Embedding 과정을 거쳐서 보다 dense하게 만들어주어야함.\n",
        "##torch.nn.Embedding(num_embeddings=len(ratings_df['mbrNo']),embedding_dim = ratings_df['mbrNo'].nunqiue())\n",
        "\n",
        "ratings_df['en_userId'] = ratings_df['mbrNo'].apply(lambda x : user_encoder[x])\n",
        "ratings_df['en_movieId'] = ratings_df['goodsNm'].apply(lambda x : item_encoder[x])\n",
        "ratings_df_final = ratings_df\n",
        "df = ratings_df[['en_userId','en_movieId','gdasScrVal']]\n",
        "\n",
        "total_item_li = set(df['en_movieId'])\n",
        "ratings_df = []\n",
        "en_user_id_li = df['en_userId'].unique()\n",
        "for en_user_id in tqdm(en_user_id_li):\n",
        "    pos_recomencder_li = df[df['en_userId'] == en_user_id]['en_movieId'].tolist()\n",
        "    neg_recomencder_li = np.random.choice(list(total_item_li - set(pos_recomencder_li)), 2 * len(pos_recomencder_li), replace = False).tolist()\n",
        "    ratings_df += [[en_user_id, en_movieId, 1] for en_movieId in pos_recomencder_li] + [[en_user_id, en_movieId, 0] for en_movieId in neg_recomencder_li]\n",
        "\n",
        "ratings_df = pd.DataFrame(ratings_df)\n",
        "ratings_df.columns = ['en_userId','en_movieId','gdasScrVal']\n",
        "\n",
        "test_df = ratings_df\n",
        "test_df.columns = ['en_userid','en_productid','rating']\n",
        "test_df.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_df: ','\\n',train_df['rating'].value_counts(),'\\n','val_df: ','\\n',val_df['rating'].value_counts(),'\\n','test_df: ','\\n',test_df['rating'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnFHLZU-H_3r",
        "outputId": "1c12de12-82e5-4c36-ac84-4b2626070d92"
      },
      "id": "EnFHLZU-H_3r",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df:  \n",
            " 0    256386\n",
            "1    121916\n",
            "Name: rating, dtype: int64 \n",
            " val_df:  \n",
            " 0    621423\n",
            "1      6277\n",
            "Name: rating, dtype: int64 \n",
            " test_df:  \n",
            " 0    17816\n",
            "1     8908\n",
            "Name: rating, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdaad107",
      "metadata": {
        "id": "cdaad107"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(df = train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, drop_last = False)\n",
        "\n",
        "valid_dataset = CustomDataset(df = val_df)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = True, drop_last = False)\n",
        "\n",
        "test_dataset = CustomDataset(df = test_df)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 100, shuffle = False, drop_last = False)\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GMF & MLP Train / Validation data로 학습"
      ],
      "metadata": {
        "id": "ZFB0kAQnqJbN"
      },
      "id": "ZFB0kAQnqJbN"
    },
    {
      "cell_type": "code",
      "source": [
        "gmf = GMF(num_user = num_user, num_item = num_item, num_factor = num_factor).to(device)\n",
        "gmf_optimizer = torch.optim.Adam(gmf.parameters(), lr = lr)\n",
        "\n",
        "mlp = MLP(num_user = num_user, num_item = num_item, num_factor = num_factor, num_layers = num_layers, dropout = dropout).to(device)\n",
        "mlp_optimizer = torch.optim.Adam(mlp.parameters(), lr = lr)\n",
        "\n",
        "loss_fc = nn.BCELoss() "
      ],
      "metadata": {
        "id": "Ig3-6byQBWL6"
      },
      "id": "Ig3-6byQBWL6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94df7040",
      "metadata": {
        "id": "94df7040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "667f853f-b707-4b95-e18d-5c7e970615d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EPOCH: 1], GMF Train Loss: 0.4394, GMF Valid Loss : 0.0001\n",
            "GMF HR: 0.3060, GMF NDCG: 0.1792\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 2], GMF Train Loss: 0.1511, GMF Valid Loss : 0.0001\n",
            "GMF HR: 0.2985, GMF NDCG: 0.1706\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 3], GMF Train Loss: 0.0171, GMF Valid Loss : 0.0002\n",
            "GMF HR: 0.3172, GMF NDCG: 0.1804\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 4], GMF Train Loss: 0.0017, GMF Valid Loss : 0.0008\n",
            "GMF HR: 0.3209, GMF NDCG: 0.1810\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 5], GMF Train Loss: 0.0002, GMF Valid Loss : 0.0005\n",
            "GMF HR: 0.3358, GMF NDCG: 0.1781\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 6], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0006\n",
            "GMF HR: 0.3470, GMF NDCG: 0.1789\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 7], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0002\n",
            "GMF HR: 0.3433, GMF NDCG: 0.1773\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 8], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0003\n",
            "GMF HR: 0.3582, GMF NDCG: 0.1784\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 9], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0011\n",
            "GMF HR: 0.3769, GMF NDCG: 0.1922\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 10], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0006\n",
            "GMF HR: 0.3843, GMF NDCG: 0.2004\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 11], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0022\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2107\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 12], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0009\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2022\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 13], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0002\n",
            "GMF HR: 0.3993, GMF NDCG: 0.1990\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 14], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0001\n",
            "GMF HR: 0.3993, GMF NDCG: 0.1991\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 15], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0006\n",
            "GMF HR: 0.4030, GMF NDCG: 0.2010\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 16], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0009\n",
            "GMF HR: 0.3993, GMF NDCG: 0.1955\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 17], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0015\n",
            "GMF HR: 0.4030, GMF NDCG: 0.1981\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 18], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0006\n",
            "GMF HR: 0.4067, GMF NDCG: 0.1993\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 19], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0009\n",
            "GMF HR: 0.4030, GMF NDCG: 0.2001\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 20], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0009\n",
            "GMF HR: 0.4030, GMF NDCG: 0.1997\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 21], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0015\n",
            "GMF HR: 0.3993, GMF NDCG: 0.1987\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 22], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0006\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2003\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 23], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0009\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2003\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 24], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0016\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2003\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 25], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0015\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2003\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 26], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0008\n",
            "GMF HR: 0.3993, GMF NDCG: 0.1989\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 27], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0019\n",
            "GMF HR: 0.3993, GMF NDCG: 0.1989\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 28], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0003\n",
            "GMF HR: 0.3993, GMF NDCG: 0.1986\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 29], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0010\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2001\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 30], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0009\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2009\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 31], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0006\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2009\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 32], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0013\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2009\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 33], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0001\n",
            "GMF HR: 0.3993, GMF NDCG: 0.2009\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 34], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0008\n",
            "GMF HR: 0.3955, GMF NDCG: 0.1999\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 35], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0008\n",
            "GMF HR: 0.3955, GMF NDCG: 0.2006\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 36], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0012\n",
            "GMF HR: 0.3955, GMF NDCG: 0.2006\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 37], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0008\n",
            "GMF HR: 0.3918, GMF NDCG: 0.1995\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 38], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0015\n",
            "GMF HR: 0.3955, GMF NDCG: 0.2010\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 39], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0002\n",
            "GMF HR: 0.3955, GMF NDCG: 0.2010\n",
            "-------------------------------------------------------- \n",
            "\n",
            "[EPOCH: 40], GMF Train Loss: 0.0000, GMF Valid Loss : 0.0008\n",
            "GMF HR: 0.3955, GMF NDCG: 0.2010\n",
            "-------------------------------------------------------- \n",
            "\n"
          ]
        }
      ],
      "source": [
        "gmf_best_metric = 0\n",
        "mlp_best_metric = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    gmf_train_loss,gmf_valid_loss = train(model = gmf, train_loader = train_loader, criterion = loss_fc, optimizer = gmf_optimizer)\n",
        "    gmf_hr, gmf_ndcg,a,b = metrics(model = gmf, test_loader = test_loader, top_k = top_k)\n",
        "\n",
        "    mlp_train_loss,mlp_valid_loss = train(model = mlp, train_loader = train_loader, criterion = loss_fc, optimizer = mlp_optimizer)\n",
        "    mlp_hr, mlp_ndcg,a,b  = metrics(model = mlp, test_loader = test_loader, top_k = top_k)\n",
        "\n",
        "    print(f\"[EPOCH: {epoch}], GMF Train Loss: {gmf_train_loss:.4f}, MLP Train Loss: {mlp_train_loss:.4f}, GMF Valid Loss : {gmf_valid_loss:.4f}, MLP Valid Loss : {mlp_valid_loss:.4f}\")\n",
        "    print(f\"GMF HR: {gmf_hr:.4f}, MLP HR: {mlp_hr:.4f}, GMF NDCG: {gmf_ndcg:.4f}, MLP NDCG: {mlp_ndcg:.4f}\")\n",
        "    print('--------------------------------------------------------','\\n')\n",
        "\n",
        "    print(f\"[EPOCH: {epoch}], GMF Train Loss: {gmf_train_loss:.4f}, GMF Valid Loss : {gmf_valid_loss:.4f}\")\n",
        "    print(f\"GMF HR: {gmf_hr:.4f}, GMF NDCG: {gmf_ndcg:.4f}\")\n",
        "    print('--------------------------------------------------------','\\n')\n",
        "\n",
        "\n",
        "    if gmf_best_metric < gmf_ndcg:\n",
        "        gmf_best_metric = gmf_ndcg\n",
        "        torch.save(gmf.state_dict(), model_dir + f'GMF.pt')\n",
        "\n",
        "    if mlp_best_metric < mlp_ndcg:\n",
        "        mlp_best_metric = mlp_ndcg\n",
        "        torch.save(mlp.state_dict(), model_dir + f'MLP.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c8409be",
      "metadata": {
        "id": "5c8409be"
      },
      "source": [
        "### NeuMF 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f0f19e75",
      "metadata": {
        "id": "f0f19e75"
      },
      "outputs": [],
      "source": [
        "# NeuMF 의 경우 pre-trained 모델을 사용한다고 함\n",
        "# 그리고 optimizer로 SGD를 사용한다고 함\n",
        "# 실제로 Adam 보다 더 좋은 성능을 보임\n",
        "\n",
        "gmf = GMF(num_user = num_user, num_item = num_item, num_factor = num_factor).to(device)\n",
        "gmf.load_state_dict(torch.load(model_dir + f'GMF.pt'))\n",
        "\n",
        "mlp = MLP(num_user = num_user, num_item = num_item, num_factor = num_factor, num_layers = num_layers, dropout = dropout).to(device)\n",
        "mlp.load_state_dict(torch.load(model_dir + f'MLP.pt'))\n",
        "\n",
        "nmf = NeuMF(GMF = gmf, MLP = mlp, num_factor = num_factor,num_layers = num_layers).to(device)\n",
        "nmf_optimizer = torch.optim.SGD(nmf.parameters(), lr = lr, momentum = 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e84996b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "0e84996b",
        "outputId": "be1e1d22-246e-4db6-97e7-fa47f0857f2d",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EPOCH: 1], NeuMF Train Loss: 0.0795,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1554\n",
            "[EPOCH: 2], NeuMF Train Loss: 0.0157,NeuMF Valid Loss: 0.0002 ,NeuMF HR: 0.2985, NeuMF NDCG: 0.1595\n",
            "[EPOCH: 3], NeuMF Train Loss: 0.0093,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2985, NeuMF NDCG: 0.1616\n",
            "[EPOCH: 4], NeuMF Train Loss: 0.0066,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2985, NeuMF NDCG: 0.1572\n",
            "[EPOCH: 5], NeuMF Train Loss: 0.0052,NeuMF Valid Loss: 0.0002 ,NeuMF HR: 0.2985, NeuMF NDCG: 0.1583\n",
            "[EPOCH: 6], NeuMF Train Loss: 0.0043,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2985, NeuMF NDCG: 0.1597\n",
            "[EPOCH: 7], NeuMF Train Loss: 0.0036,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1595\n",
            "[EPOCH: 8], NeuMF Train Loss: 0.0031,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2910, NeuMF NDCG: 0.1592\n",
            "[EPOCH: 9], NeuMF Train Loss: 0.0028,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2910, NeuMF NDCG: 0.1589\n",
            "[EPOCH: 10], NeuMF Train Loss: 0.0025,NeuMF Valid Loss: 0.0002 ,NeuMF HR: 0.2910, NeuMF NDCG: 0.1591\n",
            "[EPOCH: 11], NeuMF Train Loss: 0.0022,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2910, NeuMF NDCG: 0.1594\n",
            "[EPOCH: 12], NeuMF Train Loss: 0.0021,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2910, NeuMF NDCG: 0.1594\n",
            "[EPOCH: 13], NeuMF Train Loss: 0.0019,NeuMF Valid Loss: 0.0002 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1593\n",
            "[EPOCH: 14], NeuMF Train Loss: 0.0018,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1605\n",
            "[EPOCH: 15], NeuMF Train Loss: 0.0016,NeuMF Valid Loss: 0.0002 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1601\n",
            "[EPOCH: 16], NeuMF Train Loss: 0.0015,NeuMF Valid Loss: 0.0002 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1601\n",
            "[EPOCH: 17], NeuMF Train Loss: 0.0014,NeuMF Valid Loss: 0.0002 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1588\n",
            "[EPOCH: 18], NeuMF Train Loss: 0.0014,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1601\n",
            "[EPOCH: 19], NeuMF Train Loss: 0.0013,NeuMF Valid Loss: 0.0001 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1612\n",
            "[EPOCH: 20], NeuMF Train Loss: 0.0012,NeuMF Valid Loss: 0.0002 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1587\n",
            "[EPOCH: 21], NeuMF Train Loss: 0.0012,NeuMF Valid Loss: 0.0002 ,NeuMF HR: 0.2948, NeuMF NDCG: 0.1570\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-0aabc012a385>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnmf_train_loss_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mnmf_valid_loss_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mnmf_hr_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mnmf_ndcg_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnmf_train_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnmf_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnmf_hr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmf_ndcg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-1980f86df679>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-657144a5847e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \"\"\"\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;31m# error: Decorated property not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "nmf_best_metric = 0\n",
        "nmf_train_loss_lst = []; nmf_valid_loss_lst = []; nmf_hr_lst = []; nmf_ndcg_lst = []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    nmf_train_loss,nmf_valid_loss = train(model = nmf, train_loader = train_loader, criterion = loss_fc, optimizer = nmf_optimizer)\n",
        "    nmf_hr, nmf_ndcg,a,b = metrics(model = nmf, test_loader = test_loader, top_k = top_k)\n",
        "\n",
        "    nmf_train_loss_lst.append(nmf_train_loss);nmf_valid_loss_lst.append(nmf_valid_loss)\n",
        "    nmf_hr_lst.append(nmf_hr); nmf_ndcg_lst.append(nmf_ndcg)\n",
        "    print(f\"[EPOCH: {epoch}], NeuMF Train Loss: {nmf_train_loss:.4f},NeuMF Valid Loss: {nmf_valid_loss:.4f} ,NeuMF HR: {nmf_hr:.4f}, NeuMF NDCG: {nmf_ndcg:.4f}\")\n",
        "\n",
        "    if nmf_best_metric < nmf_ndcg:\n",
        "        nmf_best_metric = nmf_ndcg\n",
        "        torch.save(nmf.state_dict(), model_dir + f'NeuMF.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3832aa",
      "metadata": {
        "id": "ce3832aa"
      },
      "source": [
        "### 평가\n",
        "\n",
        "- 올리브영 데이터셋으로"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P4RzPg1YBTwt",
      "metadata": {
        "id": "P4RzPg1YBTwt"
      },
      "outputs": [],
      "source": [
        "oliveyoung_dataset = CustomDataset(df = test_df)\n",
        "oliveyoung_loader = DataLoader(oliveyoung_dataset, batch_size = 1, shuffle = True, drop_last = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f4d0761",
      "metadata": {
        "id": "4f4d0761",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b0b817-8739-461a-c5b9-f285d10b08cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuMF HR: 0.2985, NeuMF NDCG: 0.1616, \n",
            " MLP HR: 0.3172, MLP NDCG: 0.1745 \n",
            " GMF HR: 0.3433, GMF NDCG: 0.1808\n"
          ]
        }
      ],
      "source": [
        "nmf = NeuMF(GMF = gmf, MLP = mlp, num_factor = num_factor,num_layers=num_layers).to(device)\n",
        "nmf.load_state_dict(torch.load(model_dir + f'NeuMF.pt'))\n",
        "\n",
        "gmf = GMF(num_user = num_user, num_item = num_item, num_factor = num_factor).to(device)\n",
        "gmf.load_state_dict(torch.load(model_dir + f'GMF.pt'))\n",
        "\n",
        "mlp = MLP(num_user = num_user, num_item = num_item, num_factor = num_factor, num_layers = num_layers, dropout = dropout).to(device)\n",
        "mlp.load_state_dict(torch.load(model_dir + f'MLP.pt'))\n",
        "\n",
        "gmf_hr, gmf_ndcg,predictions,recommend = metrics(model = gmf, test_loader = test_loader, top_k = top_k)\n",
        "mlp_hr, mlp_ndcg,predictions,recommend  = metrics(model = mlp, test_loader = test_loader, top_k = top_k)\n",
        "nmf_hr, nmf_ndcg,predictions,recommend = metrics(model = nmf, test_loader = test_loader, top_k = top_k)\n",
        "\n",
        "print(f\"NeuMF HR: {nmf_hr:.4f}, NeuMF NDCG: {nmf_ndcg:.4f}, \\n MLP HR: {mlp_hr:.4f}, MLP NDCG: {mlp_ndcg:.4f} \\n GMF HR: {gmf_hr:.4f}, GMF NDCG: {gmf_ndcg:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2v1LjH_RDm1U",
      "metadata": {
        "id": "2v1LjH_RDm1U"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 생성\n",
        "- Inference 하기 위해서 한 user당 모든 아이템을 inference할 수 있도록 데이터프레임 구성"
      ],
      "metadata": {
        "id": "b3bCm2vOAYJH"
      },
      "id": "b3bCm2vOAYJH"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/BOAZ/분석/BASE/MINI2/DATA/olive_young_data.csv')"
      ],
      "metadata": {
        "id": "JMF-VsikIkIB"
      },
      "id": "JMF-VsikIkIB",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_list = []; item_list = []; rating_list = []\n",
        "item_unique = list(df['goodsNm'].unique())\n",
        "for _user in list(df['mbrNo'].unique()):\n",
        "  rating_0 = list(df[df['mbrNo']==_user].goodsNm.unique())\n",
        "  for _item in item_unique:\n",
        "    if _item in rating_0:\n",
        "      rating_list.append(1)\n",
        "      user_list.append(_user)\n",
        "      item_list.append(_item)\n",
        "    else:\n",
        "      rating_list.append(0)\n",
        "      user_list.append(_user)\n",
        "      item_list.append(_item)"
      ],
      "metadata": {
        "id": "M9X3R6gJIkzd"
      },
      "id": "M9X3R6gJIkzd",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.DataFrame({'mbrNo':user_list,'goodsNm':item_list,'gdasScrVal':rating_list})"
      ],
      "metadata": {
        "id": "BtvMOuKMImjB"
      },
      "id": "BtvMOuKMImjB",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 먼저 데이터셋 encoding\n",
        "user_encoder, user_decoder = {}, {}\n",
        "\n",
        "# label encoding이라고 생각\n",
        "for idx, user_id in enumerate(final_df['mbrNo'].unique()):\n",
        "    user_encoder[user_id] = idx\n",
        "    user_decoder[idx] = user_id\n",
        "\n",
        "# label encoding이라고 생각\n",
        "item_encoder, item_decoder = {}, {}\n",
        "for idx, item_id in enumerate(final_df['goodsNm'].unique()):\n",
        "    item_encoder[item_id] = idx\n",
        "    item_decoder[idx] = item_id\n",
        "    \n",
        "# 추후에 Embedding 과정을 거쳐서 보다 dense하게 만들어주어야함.\n",
        "##torch.nn.Embedding(num_embeddings=len(ratings_df['mbrNo']),embedding_dim = ratings_df['mbrNo'].nunqiue())\n",
        "\n",
        "final_df['en_mbrNo'] = final_df['mbrNo'].apply(lambda x : user_encoder[x])\n",
        "final_df['en_goodsNm'] = final_df['goodsNm'].apply(lambda x : item_encoder[x])\n",
        "ratings_df_final = final_df\n",
        "final_df = final_df[['en_mbrNo','en_goodsNm','gdasScrVal']]\n",
        "# ratings_df['gdasScrVal'] = ratings_df['gdasScrVal'].apply(lambda x : x//2)\n",
        "\n",
        "test_df = final_df\n",
        "test_df.columns = ['en_userid','en_productid','rating']\n",
        "test_df.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "stJC0E37Io61"
      },
      "id": "stJC0E37Io61",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oliveyoung_dataset = CustomDataset(df = test_df)\n",
        "oliveyoung_loader = DataLoader(oliveyoung_dataset, batch_size = 1, shuffle = True, drop_last = False)"
      ],
      "metadata": {
        "id": "WQ-pBmETIquQ"
      },
      "id": "WQ-pBmETIquQ",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "06c124d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06c124d1",
        "outputId": "42cc95ce-5e0b-4748-8218-061fb9510e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 338958/338958 [04:04<00:00, 1386.59it/s]\n"
          ]
        }
      ],
      "source": [
        "def inference(model,dataloader):\n",
        "  output_list = []\n",
        "  for user,item,label in tqdm(dataloader):\n",
        "        user = user.to(device)\n",
        "        item = item.to(device)\n",
        "        label = label.to(device)\n",
        "        label = label.float()\n",
        "        output = model(user, item)\n",
        "        output_list.append(output.detach().cpu().numpy())\n",
        "  return output_list\n",
        "\n",
        "pred = inference(gmf,oliveyoung_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "E_nC0qRODVXC",
      "metadata": {
        "id": "E_nC0qRODVXC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "520a8e7a-8197-47db-fc88-6dccf72b7336"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 mbrNo                                     goodsNm  \\\n",
              "0       M0000012102162  [선우PICK]메디힐 티트리 진정 패드 더블 기획 (100매+100매 리필)   \n",
              "1       M0000012102162                  [선우PICK]메디힐 티트리 진정 패드 100매   \n",
              "2       M0000012102162                     크리넥스 99.9% 항균 안심물티슈 10매   \n",
              "3       M0000012102162                                         C08   \n",
              "4       M0000012102162                                        C08\"   \n",
              "...                ...                                         ...   \n",
              "338953  M0000004588891        아이디얼 포맨 프레시 올인원 기획 (본품150ml+50ml 증정)   \n",
              "338954  M0000004588891                               필리밀리 손톱깎이 (S)   \n",
              "338955  M0000004588891       W.DRESSROOM 퍼퓸 핸드크림 No.30 화이트머스크 50ml   \n",
              "338956  M0000004588891                                   필리밀리 코털가위   \n",
              "338957  M0000004588891                         아크네스 3초 진정 패치 2종 택1   \n",
              "\n",
              "        gdasScrVal  predict_gdasScrVal  \n",
              "0                1        1.031415e-10  \n",
              "1                0        1.796726e-11  \n",
              "2                0        1.000000e+00  \n",
              "3                0        1.000000e+00  \n",
              "4                0        3.530038e-11  \n",
              "...            ...                 ...  \n",
              "338953           0        1.921792e-03  \n",
              "338954           0        3.792054e-09  \n",
              "338955           0        9.648497e-01  \n",
              "338956           0        6.523021e-06  \n",
              "338957           1        9.997398e-01  \n",
              "\n",
              "[338958 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-189acd88-bac6-424d-8fb7-5679c4b4ef00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mbrNo</th>\n",
              "      <th>goodsNm</th>\n",
              "      <th>gdasScrVal</th>\n",
              "      <th>predict_gdasScrVal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M0000012102162</td>\n",
              "      <td>[선우PICK]메디힐 티트리 진정 패드 더블 기획 (100매+100매 리필)</td>\n",
              "      <td>1</td>\n",
              "      <td>1.031415e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M0000012102162</td>\n",
              "      <td>[선우PICK]메디힐 티트리 진정 패드 100매</td>\n",
              "      <td>0</td>\n",
              "      <td>1.796726e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M0000012102162</td>\n",
              "      <td>크리넥스 99.9% 항균 안심물티슈 10매</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M0000012102162</td>\n",
              "      <td>C08</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M0000012102162</td>\n",
              "      <td>C08\"</td>\n",
              "      <td>0</td>\n",
              "      <td>3.530038e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338953</th>\n",
              "      <td>M0000004588891</td>\n",
              "      <td>아이디얼 포맨 프레시 올인원 기획 (본품150ml+50ml 증정)</td>\n",
              "      <td>0</td>\n",
              "      <td>1.921792e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338954</th>\n",
              "      <td>M0000004588891</td>\n",
              "      <td>필리밀리 손톱깎이 (S)</td>\n",
              "      <td>0</td>\n",
              "      <td>3.792054e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338955</th>\n",
              "      <td>M0000004588891</td>\n",
              "      <td>W.DRESSROOM 퍼퓸 핸드크림 No.30 화이트머스크 50ml</td>\n",
              "      <td>0</td>\n",
              "      <td>9.648497e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338956</th>\n",
              "      <td>M0000004588891</td>\n",
              "      <td>필리밀리 코털가위</td>\n",
              "      <td>0</td>\n",
              "      <td>6.523021e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338957</th>\n",
              "      <td>M0000004588891</td>\n",
              "      <td>아크네스 3초 진정 패치 2종 택1</td>\n",
              "      <td>1</td>\n",
              "      <td>9.997398e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>338958 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-189acd88-bac6-424d-8fb7-5679c4b4ef00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-189acd88-bac6-424d-8fb7-5679c4b4ef00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-189acd88-bac6-424d-8fb7-5679c4b4ef00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# 아래와 같이 user가 어떤 제품에 평점을 몇점 정도 매길지 확인이 가능.\n",
        "pred_df = ratings_df_final[['mbrNo','goodsNm','gdasScrVal']]\n",
        "pred_df['predict_gdasScrVal'] = [float(pr[0]) for pr in pred]\n",
        "pred_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "res = []; user_lst = []; pred_rate = []\n",
        "for _user in tqdm(list(pred_df['mbrNo'].unique())):\n",
        "  temp = pred_df[pred_df['mbrNo']==_user]\n",
        "  final_temp = temp[temp['gdasScrVal']==0]\n",
        "  res.append(list(final_temp[final_temp['mbrNo']==_user].sort_values(by='predict_gdasScrVal',ascending=False)[:5].goodsNm))\n",
        "  pred_rate.append(list(final_temp[final_temp['mbrNo']==_user].sort_values(by='predict_gdasScrVal',ascending=False)[:5].predict_gdasScrVal))\n",
        "  user_lst.append(_user)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWxas9OUVlCV",
        "outputId": "e65ab6af-0e3e-4161-f09a-1072910ecc79"
      },
      "id": "dWxas9OUVlCV",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6277/6277 [02:17<00:00, 45.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_df = pd.DataFrame({'userId':user_lst, 'top_5_name':res,'prediction_rate':pred_rate})\n",
        "res_df.to_csv('NCF_Res_GMF.csv',index=False)"
      ],
      "metadata": {
        "id": "V1wKmBNA66zF"
      },
      "id": "V1wKmBNA66zF",
      "execution_count": 42,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}